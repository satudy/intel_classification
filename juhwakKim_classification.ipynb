{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled3.ipynb","version":"0.3.2","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"got184eD9Rrm","colab_type":"text"},"source":["## kaggle 설치 및 폴더 추가"]},{"cell_type":"code","metadata":{"id":"uW2oe0ls4EDl","colab_type":"code","colab":{}},"source":["!pip install kaggle\n","!pip install hyperas\n","!pip install hyperopt\n","!mkdir .kaggle"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gIGVM2Ug9kbK","colab_type":"text"},"source":["## Kaggle Profile에서 Create New Api token 으로 json파일 받기\n","\n","json 파일에서 username과 key 다운받기"]},{"cell_type":"code","metadata":{"id":"y4Utgqb74pk7","colab_type":"code","colab":{}},"source":["import json\n","token = {\"username\":\"juhk1017\",\"key\":\"6c8f2081b6dc5d4f090e69dbd9436528\"}\n","with open('/content/.kaggle/kaggle.json', 'w') as file:\n","    json.dump(token, file)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4ogz3SBm_F6b","colab_type":"text"},"source":["## 왠지 모르겠는데 이부분 2번 실행시켜줘야함"]},{"cell_type":"code","metadata":{"id":"deIi_3hM5kYS","colab_type":"code","colab":{}},"source":["!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n","!kaggle config set -n path -v{/content}\n","\n","!chmod 600 /content/.kaggle/kaggle.json"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CpUcSGEb-d73","colab_type":"text"},"source":["## 원하는 dataset의 페이지에서 New Kernel 옆 ...을 클릭후 copy api command 로 코드 복사"]},{"cell_type":"code","metadata":{"id":"9KszO4zc5p-J","colab_type":"code","colab":{}},"source":["!kaggle datasets download -d puneet6060/intel-image-classification -p /content #아마 kaggle datasets download -d puneet6060/intel-image-classification 이런식으로 복사 될거임\n","\n","!unzip \\intel-image-classification.zip\n","!unzip \\seg_train.zip\n","!unzip \\seg_test.zip\n","!unzip \\seg_pred.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jP4e1u_t_iMU","colab_type":"code","colab":{}},"source":["!ls #현재 디렉터리안에 Data file 들이 다운받아지고 압축이 풀려 있는 것을 확인할 수 있다."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ACsGJJEBH-wm","colab_type":"text"},"source":["## hyperas를 colab에서 사용하기에 필요"]},{"cell_type":"code","metadata":{"id":"tkcNB-Eao_AG","colab_type":"code","colab":{}},"source":["# Install the PyDrive wrapper & import libraries.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Copy/download the file\n","fid = drive.ListFile({'q':\"title='Untitled3.ipynb'\"}).GetList()[0]['id']\n","f = drive.CreateFile({'id': fid})\n","f.GetContentFile('Untitled3.ipynb')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"St1YvVSpCdbA","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import numpy as np\n","import os\n","from keras.models import Sequential,Model\n","from keras.layers import LSTM, Dense, TimeDistributed,CuDNNLSTM,BatchNormalization,Flatten,Dropout,Activation\n","from keras.layers import Input,concatenate\n","\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.utils import to_categorical\n","from keras.callbacks import ModelCheckpoint\n","import keras\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.regularizers import l2\n","\n","from sklearn.utils import shuffle\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split\n","\n","import matplotlib.pyplot as plot\n","import tensorflow as tf\n","import cv2\n","import glob\n","\n","from hyperas.distributions import uniform,choice\n","from hyperopt import Trials, STATUS_OK, tpe\n","from hyperas import optim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"akRO15YB7VAH","colab_type":"code","colab":{}},"source":["def get_images(dir):\n","    images = []\n","    Labels = []\n","    \n","    for labels in os.listdir(dir):\n","        print(labels)\n","        if labels == 'buildings': \n","            label = 0\n","        elif labels == 'forest':\n","            label = 1\n","        elif labels == 'glacier':\n","            label = 2\n","        elif labels == 'mountain':\n","            label = 3\n","        elif labels == 'sea':\n","            label = 4\n","        elif labels == 'street':\n","            label = 5\n","        #print(dir+ '/' + labels)\n","        for image_file in glob.glob(dir+ '/' + labels + '/*.jpg'): \n"," \n","            image = cv2.imread(image_file)\n","            image = cv2.resize(image,(64,64)) \n","        \n","            images.append(image)\n","            Labels.append(label)\n","        \n","        \n","    return shuffle(images,Labels)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nSBr20347ufJ","colab_type":"code","colab":{}},"source":["images, Labels = get_images('seg_train')\n","\n","images = np.array(images) #converting the list of images to numpy array.\n","Labels = np.array(Labels)\n","\n","print(\"Shape of Images:\",images.shape)\n","print(\"Shape of Labels:\",Labels.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M7vb7bkAz7Q7","colab_type":"code","colab":{}},"source":["    X_train, Y_train = get_images('seg_train')\n","    X_test, Y_test  = get_images('seg_test')\n","    Y_train = keras.utils.to_categorical(Y_train,num_classes=6, dtype='float32')\n","    Y_test = keras.utils.to_categorical(Y_test,num_classes=6, dtype='float32')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8JUSMZSikoQ","colab_type":"code","colab":{}},"source":["def data():\n","\n","      X_train, Y_train = get_images('seg_train')\n","      X_test, Y_test  = get_images('seg_test')\n","      \n","      X_train = np.array(X_train)\n","      X_test = np.array(X_test)\n","      Y_train = np.array(Y_train)\n","      Y_test = np.array(Y_test)\n","      \n","      Y_train = keras.utils.to_categorical(Y_train,num_classes=6, dtype='float32')\n","      Y_test = keras.utils.to_categorical(Y_test,num_classes=6, dtype='float32')\n","      \n","      return X_train,Y_train,X_test,Y_test\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWi2-RizjUi8","colab_type":"code","colab":{}},"source":["def model(X_train,Y_train,X_test,Y_test):\n","    batch_size = 32\n","    nb_epoch = 20\n","\n","    model = Sequential()\n","    \n","    model.add(Conv2D({{choice([128, 200, 256])}},kernel_size=(3,3),activation='relu',input_shape=(64,64,3)))\n","    model.add(Conv2D({{choice([128, 180, 256])}},kernel_size=(3,3),activation='relu'))\n","    model.add(MaxPooling2D(3,3))\n","    model.add(Conv2D({{choice([128, 180, 256])}},kernel_size=(3,3),activation='relu'))\n","    model.add(Conv2D({{choice([64, 140, 200])}},kernel_size=(3,3),activation='relu'))\n","    model.add(Conv2D({{choice([64, 100, 128])}},kernel_size=(3,3),activation='relu'))\n","    model.add(Conv2D({{choice([50, 64, 128])}},kernel_size=(3,3),activation='relu'))\n","    model.add(MaxPooling2D(3,3))\n","    model.add(Flatten())\n","    model.add(Dense(180,activation='relu'))\n","    model.add(Dense(100,activation='relu'))\n","    model.add(Dense(50,activation='relu'))\n","    model.add(Dropout({{uniform(0.2, 0.8)}}))\n","    model.add(Dense(6,activation='softmax'))\n","    model.summary()\n","\n","    # let's train the model using SGD + momentum (how original).\n","    model.compile(loss='categorical_crossentropy',\n","                  optimizer=keras.optimizers.Adam(lr=0.0001),\n","                  metrics=['accuracy'])\n","\n","    # fit the model on the batches generated by datagen.flow()\n","    model.fit(X_train,Y_train,batch_size=128,epochs=nb_epoch, verbose=1,validation_data=(X_test,Y_test))\n","    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n","\n","    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6hMGZoZvCj5I","colab_type":"code","colab":{}},"source":["  X_train, Y_train, X_test, Y_test = data()\n","\n","  best_run, best_model = optim.minimize(model=model,\n","                                        data=data,\n","                                        algo=tpe.suggest,\n","                                        max_evals=4,\n","                                        functions=[get_images],\n","                                        notebook_name='Untitled3', #colab용\n","                                        trials=Trials())\n","\n","  print(\"Evalutation of best performing model:\")\n","  print(best_model.evaluate(X_test, Y_test))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3y5UIgIrClwv","colab_type":"code","colab":{}},"source":["input_1 = Input(shape=(150, 150, 3))\n","\n","x_1 = Conv2D(64, kernel_size=3,kernel_regularizer=l2(0.001))(input_1)\n","x_1 = BatchNormalization()(x_1)\n","x_1 = Activation('relu')(x_1)\n","x_1 = MaxPooling2D(pool_size=(5, 5), strides=(2, 2))(x_1)\n","\n","x_1 = Conv2D(64, kernel_size=3, kernel_regularizer=l2(0.0001))(x_1)\n","x_1 = BatchNormalization()(x_1)\n","x_1 = Activation('relu')(x_1)\n","x_1 = Conv2D(64, kernel_size=3,kernel_regularizer=l2(0.0001))(x_1)\n","x_1 = BatchNormalization()(x_1)\n","x_1 = Activation('relu')(x_1)\n","x_1 = Conv2D(64, kernel_size=3,kernel_regularizer=l2(0.0001))(x_1)\n","x_1 = BatchNormalization()(x_1)\n","x_1 = Activation('relu')(x_1)\n","x_1 = MaxPooling2D(pool_size=(5, 5), strides=(2, 2))(x_1)\n","\n","\n","\n","x_1 = Flatten()(x_1)\n","x_1 = Dense(units=180)(x_1)\n","x_1 = BatchNormalization()(x_1)\n","x_1 = Activation('relu')(x_1)\n","x_1 = Dense(units=128)(x_1)\n","x_1 = Dense(units=128)(x_1)\n","x_1 = Dropout(0.4)(x_1)\n","x_1 = Dense(units=6,activation= 'softmax')(x_1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WnvOTCYXCtph","colab_type":"code","colab":{}},"source":["cb_checkpoint = ModelCheckpoint(filepath='model_3.hdf5',\n","                                verbose=1,save_best_only=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YEldiw_OCoHo","colab_type":"code","colab":{}},"source":["model = Model(inputs=input_1,outputs=x_1)\n","\n","model.compile(loss='categorical_crossentropy',\n","                optimizer=keras.optimizers.Adam(lr=0.0001),\n","                metrics=['accuracy'])\n","\n","model.summary()\n","\n","trained = model.fit(images,Labels,epochs=35,batch_size=128,validation_split=0.30,callbacks=[cb_checkpoint])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7uwI0gA6S5LI","colab_type":"code","colab":{}},"source":["plot.plot(trained.history['acc'])\n","plot.plot(trained.history['val_acc'])\n","plot.title('Model accuracy')\n","plot.ylabel('Accuracy')\n","plot.xlabel('Epoch')\n","plot.legend(['Train', 'Test'], loc='upper left')\n","plot.show()\n","\n","plot.plot(trained.history['loss'])\n","plot.plot(trained.history['val_loss'])\n","plot.title('Model loss')\n","plot.ylabel('Loss')\n","plot.xlabel('Epoch')\n","plot.legend(['Train', 'Test'], loc='upper left')\n","plot.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xnL3e2PyrGB5","colab_type":"text"},"source":["## TEST"]},{"cell_type":"code","metadata":{"id":"BbaoldkIPdn6","colab_type":"code","colab":{}},"source":["img_test, test_label = get_images('seg_test')\n","\n","img_test = np.array(img_test) \n","test_label = np.array(test_label)\n","\n","test_label = keras.utils.to_categorical(test_label,num_classes=6, dtype='float32')\n","\n","print(\"Shape of Images:\",img_test.shape)\n","print(\"Shape of Labels:\",test_label.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nbsJC44uPFfF","colab_type":"code","colab":{}},"source":["\n","model = keras.models.load_model('model_2.hdf5') \n","model.summary()\n","loss, acc = model.evaluate(img_test, test_label)\n","print(loss)\n","print(acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LGSk5gMENZ-J","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0Dp314wUr7X-","colab_type":"text"},"source":["##Download\n"]},{"cell_type":"code","metadata":{"id":"FkTvcjaID0sU","colab_type":"code","colab":{}},"source":["from google.colab import files\n","files.download('model_1.hdf5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"w4sfInOGNgZf","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_zUEZV6aO3D1","colab_type":"code","colab":{}},"source":["!ls /gdrive/My\\ Drive/Colab\\ Notebooks/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5rleUAnOYzG","colab_type":"code","colab":{}},"source":["! cp model_2.hdf5 /gdrive/My\\ Drive/Colab\\ Notebooks/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IX4yr_H060O_","colab_type":"code","colab":{}},"source":["!pwd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJUd72gNOe3G","colab_type":"code","colab":{}},"source":["! cp /gdrive/My\\ Drive/Colab\\ Notebooks/model.hdf5 ./"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oh5R5I61tJzr","colab_type":"code","colab":{}},"source":["model = keras.models.load_model('model.hdf5') \n","model.summary()\n","loss, acc = model.evaluate(img_test, test_label)\n","print(loss)\n","print(acc)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywLks8_i7Qou","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}